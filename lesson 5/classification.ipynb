{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "\n",
    "lr = LogisticRegression(random_state=42)\n",
    "knn = KNeighborsClassifier()\n",
    "dt = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "ada = AdaBoostClassifier()\n",
    "xgb = XGBClassifier(eval_metric='logloss')\n",
    "sgd = SGDClassifier(loss='log_loss', random_state=42)\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "# parameter for KNN\n",
    "para_knn={'n_neighbors':np.arange(1,50)}\n",
    "grid_knn=GridSearchCV(knn,param_grid=para_knn,cv=5)\n",
    "\n",
    "#parameter for decision tree\n",
    "para_dt={'criterion':['gini','entropy'],'max_depth':np.arange(1,50),\n",
    "         'min_samples_leaf':[1,2,4,5,10,20,30,40,50,80,100]}\n",
    "grid_dt=GridSearchCV(dt,param_grid=para_dt,cv=5)\n",
    "\n",
    "#parameter for Random Forest\n",
    "params_rf={'n_estimators':[100,200,350,500],\n",
    "           'min_samples_leaf':[2,10,30,50,80,100]}\n",
    "grid_rf=GridSearchCV(rf,param_grid=params_rf,cv=5)\n",
    "\n",
    "#parameters for AdaBoost\n",
    "params_ada={\n",
    "    'algorithm': ['SAMME'],\n",
    "    'n_estimators':[50,100,250,400,500],\n",
    "    'learning_rate':[0.1,0.001,0.2,0.5,0.8,1]}\n",
    "grid_ada=GridSearchCV(ada,param_grid=params_ada,cv=5)\n",
    "\n",
    "# paraameter for XGBoost\n",
    "params_xgb={'n_estimators':[50,100,250,600,800,1000],\n",
    "           'learning_rate':[0.1,0.001,0.2,0.5,0.8,1]}\n",
    "rs_xgb=RandomizedSearchCV(xgb,param_distributions=params_xgb,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df.drop([\"Survived\"], axis=1)\n",
    "y_train = train_df[\"Survived\"]\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.3, random_state=42, stratify=y_train)\n",
    "\n",
    "grid_dt.fit(x_train,y_train)\n",
    "grid_rf.fit(x_train,y_train)\n",
    "grid_ada.fit(x_train,y_train)\n",
    "rs_xgb.fit(x_train,y_train)\n",
    "sgd.fit(x_train,y_train)\n",
    "lda.fit(x_train,y_train)\n",
    "qda.fit(x_train,y_train)\n",
    "\n",
    "print(\"Best parameters for Decision Tree:\", grid_dt.best_params_)\n",
    "print(\"Best parameters for Random Forest:\", grid_rf.best_params_)\n",
    "print(\"Best parameters for AdaBoost:\", grid_ada.best_params_)\n",
    "print(\"Best parameters for XGBoost:\", rs_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = grid_dt.best_estimator_\n",
    "rf = grid_rf.best_estimator_\n",
    "ada = grid_ada.best_estimator_\n",
    "xgb = rs_xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [('Decision Tree', dt), ('Random Forest', rf), ('AdaBoost', ada),\n",
    "               ('XGBoost', xgb), ('SGD', sgd), ('LDA', lda), ('QDA', qda)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "for classifier_name, classifier in classifiers:\n",
    "    # fit classifier\n",
    "#     classifier.fit(x_train, y_train)\n",
    "    \n",
    "    # predict labels for test set\n",
    "    y_pred = classifier.predict(x_val)\n",
    "    \n",
    "    print(f'{classifier_name} classification report')\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    \n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    ax = plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax=ax, cmap='Blues')\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('Actual')\n",
    "    ax.set_title(classifier_name)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
