{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have you ever wanted to make your text messages more expressive? Your emojifier app will help you do that. \n",
    "Rather than writing:\n",
    ">\"Congratulations on the promotion! Let's get coffee and talk. Love you!\"   \n",
    "\n",
    "The emojifier can automatically turn this into:\n",
    ">\"Congratulations on the promotion! üëç  Let's get coffee and talk. ‚òïÔ∏è Love you! ‚ù§Ô∏è\"\n",
    "\n",
    "You'll implement a model which inputs a sentence (such as \"Let's go see the baseball game tonight!\") and finds the most appropriate emoji to be used with this sentence (‚öæÔ∏è).\n",
    "\n",
    "### Using Word Vectors to Improve Emoji Lookups\n",
    "* In many emoji interfaces, you need to remember that ‚ù§Ô∏è  is the \"heart\" symbol rather than the \"love\" symbol. \n",
    "    * In other words, you'll have to remember to type \"heart\" to find the desired emoji, and typing \"love\" won't bring up that symbol.\n",
    "* You can make a more flexible emoji interface by using word vectors!\n",
    "* When using word vectors, you'll see that even if your training set explicitly relates only a few words to a particular emoji, your algorithm will be able to generalize and associate additional words in the test set to the same emoji.\n",
    "    * This works even if those additional words don't even appear in the training set. \n",
    "    * This allows you to build an accurate classifier mapping from sentences to emojis, even using a small training set. \n",
    "\n",
    "### What you'll build:\n",
    "1. In this exercise, you'll start with a baseline model (Emojifier-V1) using word embeddings.\n",
    "2. Then you will build a more sophisticated model (Emojifier-V2) that further incorporates an LSTM. \n",
    "\n",
    "By the end of this notebook, you'll be able to:\n",
    "\n",
    "* Create an embedding layer in Keras with pre-trained word vectors\n",
    "* Explain the advantages and disadvantages of the GloVe algorithm\n",
    "* Describe how negative sampling learns word vectors more efficiently than other methods\n",
    "* Build a sentiment classifier using word embeddings\n",
    "* Build and train a more sophisticated classifier using an LSTM\n",
    "\n",
    "üèÄ üëë\n",
    "\n",
    "üëÜ üòé\n",
    "\n",
    "(^^^ Emoji for \"skills\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Only the TensorFlow backend supports string inputs.\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from tensorflow import data as tf_data\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from emo_utils import *\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset: EMOJISET \n",
    "\n",
    "You have a tiny dataset (X, Y) where:\n",
    "- X contains 127 sentences (strings).\n",
    "- Y contains an integer label between 0 and 4 corresponding to an emoji for each sentence.\n",
    "\n",
    "<img src=\"images/data_set.png\" style=\"width:700px;height:300px;\">\n",
    "\n",
    "Load the dataset using the code below. The dataset is split between training (127 examples) and testing (56 examples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/train_emoji.csv', names=[\"sentence\", \"emoji\", \"remove1\", \"remove_2\"])\n",
    "data.drop(columns=[\"remove1\", \"remove_2\"], inplace=True)\n",
    "data_test = pd.read_csv('data/tesss.csv', names=[\"sentence\", \"emoji\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = data[\"sentence\"], data[\"emoji\"]\n",
    "X_test, y_test = data_test[\"sentence\"], data_test[\"emoji\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "never talk to me again üòû\n",
      "I am proud of your achievements üòÑ\n",
      "It is the worst day in my life üòû\n",
      "Miss you so much ‚ù§Ô∏è\n",
      "food is life üç¥\n",
      "I love you mum ‚ù§Ô∏è\n",
      "Stop saying bullshit üòû\n",
      "congratulations on your acceptance üòÑ\n",
      "The assignment is too long  üòû\n",
      "I want to go play ‚öæÔ∏è\n"
     ]
    }
   ],
   "source": [
    "for idx in range(10):\n",
    "    print(X_train[idx], label_to_emoji(y_train[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below code cell, you will find out the sentence with the maximum number of words, and will store it's length in `maxLen` (*i.e., the number of words in the longest sentence, which will be used further*). Let's break down this code for a better understanding.\n",
    "\n",
    "- The first point to note here is that `split()` breaks a string into a list of it's words. So, if `x` is a string, then `len(x.split())` returns the number of words in that string. You can read more about `split` [here](https://docs.python.org/3/library/stdtypes.html?highlight=split#str.split).\n",
    "\n",
    "- The second point to note here is the way in which `max` function has been used. As can be read [here](https://docs.python.org/3/library/functions.html#max), apart from an iterable (*which in your case is `X_train`, a list of strings*), this function also has a `key` argument, that can be used to modify the basis on which the largest element in the iterable is chosen.\n",
    "\n",
    "In this case, `key` has been chosen as the number of words in a string. So the `max` function will return the string with the largest number of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxLen = len(max(X_train, key=lambda x: len(x.split())).split())\n",
    "maxLen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Vocabulary index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = keras.layers.TextVectorization(max_tokens=40000, output_sequence_length=10)\n",
    "text_ds = tf_data.Dataset.from_tensor_slices(X_train)\n",
    "vectorizer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'i', 'you', 'is']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_vocabulary()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_vocabulary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  1,  1, 39,  5,  1], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = vectorizer([[\"the cat sat on the mat\"]])\n",
    "output.numpy()[0, :6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 21, 10, 209, 227, 27]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [\"i\", \"love\", \"to\",  \"eat\", \"chinese\", \"food\"]\n",
    "[word_index[w] for w in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot Encoding\n",
    "* To get your labels into a format suitable for training a softmax classifier, convert $Y$ from its current shape  $(m, 1)$ into a \"one-hot representation\" $(m, 5)$, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = keras.utils.to_categorical(y_train)\n",
    "test_labels = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 'I missed you' has label index 0, which is emoji ‚ù§Ô∏è\n",
      "Label index 0 in one-hot encoding format is [1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "idx = 50\n",
    "print(f\"Sentence '{X_train[idx]}' has label index {y_train[idx]}, which is emoji {label_to_emoji(y_train[idx])}\", )\n",
    "print(f\"Label index {y_train[idx]} in one-hot encoding format is {train_labels[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trained word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.45281  -0.50108  -0.53714  -0.015697  0.22191   0.54602  -0.67301\n",
      " -0.6891    0.63493  -0.19726   0.33685   0.7735    0.90094   0.38488\n",
      "  0.38367   0.2657   -0.08057   0.61089  -1.2894   -0.22313  -0.61578\n",
      "  0.21697   0.35614   0.44499   0.60885  -1.1633   -1.1579    0.36118\n",
      "  0.10466  -0.78325   1.4352    0.18629  -0.26112   0.83275  -0.23123\n",
      "  0.32481   0.14485  -0.44552   0.33497  -0.95946  -0.097479  0.48138\n",
      " -0.43352   0.69455   0.91043  -0.28173   0.41637  -1.2609    0.71278\n",
      "  0.23782 ]\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "path_to_glove_file = \"data/glove.6B.50d.txt\"\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(embeddings_index[\"cat\"])\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " However, most deep learning frameworks require that all sequences in the same mini-batch have the **same length**. \n",
    "\n",
    "This is what allows vectorization to work: If you had a 3-word sentence and a 4-word sentence, then the computations needed for them are different (one takes 3 steps of an LSTM, one takes 4 steps) so it's just not possible to do them both at the same time.\n",
    "    \n",
    "#### Padding Handles Sequences of Varying Length\n",
    "* The common solution to handling sequences of **different length** is to use padding.  Specifically:\n",
    "    * Set a maximum sequence length\n",
    "    * Pad all sequences to have the same length. \n",
    "    \n",
    "#### Example of Padding:\n",
    "* Given a maximum sequence length of 20, you could pad every sentence with \"0\"s so that each input sentence is of length 20. \n",
    "* Thus, the sentence \"I love you\" would be represented as $(e_{I}, e_{love}, e_{you}, \\vec{0}, \\vec{0}, \\ldots, \\vec{0})$. \n",
    "* In this example, any sentences longer than 20 words would have to be truncated. \n",
    "* One way to choose the maximum sequence length is to just pick the length of the longest sentence in the training set. \n",
    "  \n",
    "### The Embedding Layer\n",
    "\n",
    "In Keras, the embedding matrix is represented as a \"layer.\"\n",
    "\n",
    "* The embedding matrix maps word indices to embedding vectors.\n",
    "    * The word indices are positive integers.\n",
    "    * The embedding vectors are dense vectors of fixed size.\n",
    "    * A \"dense\" vector is the opposite of a sparse vector. It means that most of its values are non-zero.  As a counter-example, a one-hot encoded vector is not \"dense.\"\n",
    "* The embedding matrix can be derived in two ways:\n",
    "    * Training a model to derive the embeddings from scratch. \n",
    "    * Using a pretrained embedding.\n",
    "    \n",
    "#### Using and Updating Pre-trained Embeddings\n",
    "In this section, you'll create an [Embedding()](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding) layer in Keras\n",
    "\n",
    "* You will initialize the Embedding layer with GloVe 50-dimensional vectors. \n",
    "* In the code below, you'll observe how Keras allows you to either train or leave this layer fixed.  \n",
    "    * Because your training set is quite small, you'll leave the GloVe embeddings fixed instead of updating them.\n",
    "\n",
    "#### Inputs and Outputs to the Embedding Layer\n",
    "\n",
    "* The `Embedding()` layer's input is an integer matrix of size **(batch size, max input length)**. \n",
    "    * This input corresponds to sentences converted into lists of indices (integers).\n",
    "    * The largest integer (the highest word index) in the input should be no larger than the vocabulary size.\n",
    "* The embedding layer outputs an array of shape (batch size, max input length, dimension of word vectors).\n",
    "\n",
    "* The figure shows the propagation of two example sentences through the embedding layer. \n",
    "    * Both examples have been zero-padded to a length of `max_len=5`.\n",
    "    * The word embeddings are 50 units in length.\n",
    "    * The final dimension of the representation is  `(2,max_len,50)`. \n",
    "\n",
    "<img src=\"images/embedding1.png\" style=\"width:700px;height:250px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 260 words (2 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(embeddings_index) + 2\n",
    "embedding_dim = 50\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = keras.layers.Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    trainable=False,\n",
    ")\n",
    "embedding_layer.build((1,))\n",
    "embedding_layer.set_weights([embedding_matrix])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Model Overview\n",
    "\n",
    "Here is the Emojifier-v2 you will implement:\n",
    "\n",
    "<img src=\"images/emojifier-v2.png\" style=\"width:700px;height:400px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_23 (InputLayer)       [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, None, 50)          20000100  \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, None, 128)         91648     \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, None, 128)         0         \n",
      "                                                                 \n",
      " lstm_18 (LSTM)              (None, 128)               131584    \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,223,977\n",
      "Trainable params: 223,877\n",
      "Non-trainable params: 20,000,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "int_sequences_input = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "embedded_sequences = embedding_layer(int_sequences_input)\n",
    "\n",
    "# Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n",
    "# The returned output should be a batch of sequences.\n",
    "X = keras.layers.LSTM(128, return_sequences=True)(embedded_sequences)\n",
    "\n",
    "# Add dropout with a probability of 0.5\n",
    "X =  keras.layers.Dropout(0.5)(X)\n",
    "\n",
    "# Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
    "# The returned output should be a single hidden state, not a batch of sequences.\n",
    "X =  keras.layers.LSTM(128)(X)\n",
    "# Add dropout with a probability of 0.5\n",
    "X =  keras.layers.Dropout(0.5)(X)\n",
    "\n",
    "# Propagate X through a Dense layer with 5 units\n",
    "outputs =  keras.layers.Dense(5)(X)\n",
    "\n",
    "model = keras.Model(int_sequences_input, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorizer(np.array([[s] for s in X_train])).numpy()\n",
    "# x_val = vectorizer(np.array([[s] for s in val_samples])).numpy()\n",
    "\n",
    "y_train = np.array(train_labels)\n",
    "# y_val = np.array(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 10), dtype=int64, numpy=\n",
       "array([[ 33,  64,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [ 43, 140,  34,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [ 27,   4, 131,  12,   3,   0,   0,   0,   0,   0]], dtype=int64)>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer([\"funny lol\", \"lets play baseball\", \"food is ready for you\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 5s 30ms/step - loss: 1.5923 - accuracy: 0.2727\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.5232 - accuracy: 0.3182\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.4710 - accuracy: 0.2955\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1.3887 - accuracy: 0.4470\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.3052 - accuracy: 0.4848\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.1948 - accuracy: 0.5985\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.0907 - accuracy: 0.6136\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.0371 - accuracy: 0.6439\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.0132 - accuracy: 0.6439\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.8083 - accuracy: 0.7348\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6905 - accuracy: 0.7576\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6805 - accuracy: 0.7197\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.5752 - accuracy: 0.7879\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.5236 - accuracy: 0.8258\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.4810 - accuracy: 0.7955\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.4309 - accuracy: 0.8409\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.3856 - accuracy: 0.8788\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.4131 - accuracy: 0.8182\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.3495 - accuracy: 0.8864\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3687 - accuracy: 0.8788\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.3204 - accuracy: 0.9015\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2872 - accuracy: 0.9091\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3655 - accuracy: 0.8712\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.3062 - accuracy: 0.8864\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2206 - accuracy: 0.9318\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2034 - accuracy: 0.9394\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1384 - accuracy: 0.9621\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2323 - accuracy: 0.9242\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.2196 - accuracy: 0.9242\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1699 - accuracy: 0.9470\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1080 - accuracy: 0.9621\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1933 - accuracy: 0.9242\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2570 - accuracy: 0.9167\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1144 - accuracy: 0.9621\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1135 - accuracy: 0.9697\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1097 - accuracy: 0.9621\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0687 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1437 - accuracy: 0.9621\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1318 - accuracy: 0.9545\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1020 - accuracy: 0.9697\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1278 - accuracy: 0.9545\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.3540 - accuracy: 0.8788\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2854 - accuracy: 0.9242\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.4166 - accuracy: 0.8788\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2979 - accuracy: 0.9167\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1000 - accuracy: 0.9848\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1027 - accuracy: 0.9773\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0992 - accuracy: 0.9773\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0740 - accuracy: 0.9773\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.0554 - accuracy: 0.9924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2696f395940>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.CategoricalCrossentropy(from_logits=True), optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=50, batch_size = 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 8ms/step - loss: 0.9256 - accuracy: 0.6964\n",
      "\n",
      "Test accuracy =  0.6964285969734192\n"
     ]
    }
   ],
   "source": [
    "x_test = vectorizer(np.array([[s] for s in X_test])).numpy()\n",
    "loss, acc = model.evaluate(x_test, test_labels)\n",
    "print()\n",
    "print(\"Test accuracy = \", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected emoji:üòÑ prediction: he got a very nice raiseüòû\n",
      "Expected emoji:üòÑ prediction: she got me a nice present‚ù§Ô∏è\n",
      "Expected emoji:üòû prediction: This girl is messing with me‚ù§Ô∏è\n",
      "Expected emoji:üòÑ prediction: Congratulation for having a baby‚ù§Ô∏è\n",
      "Expected emoji:üòÑ prediction: you brighten my day‚ù§Ô∏è\n",
      "Expected emoji:üç¥ prediction: I boiled riceüòû\n",
      "Expected emoji:üòû prediction: she is a bully‚ù§Ô∏è\n",
      "Expected emoji:‚ù§Ô∏è prediction: My grandmother is the love of my lifeüòÑ\n",
      "Expected emoji:üòÑ prediction: will you be my valentine‚ù§Ô∏è\n",
      "Expected emoji:‚öæÔ∏è prediction: he can pitch really wellüòû\n",
      "Expected emoji:üòÑ prediction: I like to laugh‚ù§Ô∏è\n",
      "Expected emoji:üòÑ prediction: What you did was awesomeüòû\n",
      "Expected emoji:üòû prediction: go away‚öæÔ∏è\n",
      "Expected emoji:üòû prediction: yesterday we lost again‚öæÔ∏è\n",
      "Expected emoji:‚ù§Ô∏è prediction: family is all I haveüòû\n",
      "Expected emoji:üòÑ prediction: You deserve this nice prizeüòû\n",
      "Expected emoji:üç¥ prediction: I did not have breakfast üòû\n"
     ]
    }
   ],
   "source": [
    "# This code allows you to see the mislabelled examples\n",
    "string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
    "x = vectorizer(string_input)\n",
    "x = model(x)\n",
    "# Add a softmax activation\n",
    "outputs =  keras.layers.Activation('softmax')(x)\n",
    "end_to_end_model = keras.Model(string_input, outputs)\n",
    "\n",
    "probabilities = end_to_end_model(\n",
    "        tf.convert_to_tensor(X_test)\n",
    ")\n",
    "for i in range(len(X_test)):\n",
    "    num = np.argmax(probabilities[i])\n",
    "    if(num != y_test[i]):\n",
    "        print('Expected emoji:'+ label_to_emoji(y_test[i]) + ' prediction: '+ X_test[i] + label_to_emoji(num).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
